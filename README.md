# similar-images

Use LLMs to search for images.

Searching for images can be a time consuming process, even with filters -
manually using a search engine and downloading images one by one can be tedious,
and having to look at many images to find the right one can be time consuming.

Similar Images cuts down on the time you need to spend on these tasks.
First, it interacts with search engines on your behalf - you only describe what you
want and let it search and download.
Second, it provides a range of filters to cut down on the number of images that are
not relevant.

# Use cases

## Expand your collection of images

Automates the use of Bing Images to find and download images.
2 modes are supported:
- Keyword search.
- Similar image search. Provide a list of images stored locally.
  Similar Images will go over them one by one and use Bing's "Search using an image" functionality to find similar images.

Some of the filters that you can use:
- Image size.
- Similarity to existing images in your collection. Image Search can use and fill a local database keeping track of local images. It can then detect when a new image is identical to or similar to an existing image, by using different hashing algorithms.
- LLMs. Many images won't match your criteria -- they might have watermark or be generated by AI, for instance. You can specify your LLM prompts and the model that you want to use to filter out non relevant images.

Whenever one writes LLM prompts, one needs to be evaluate their quality.
In order to do that, Similar Images can be run in a third mode of operation,
in which the pipeline of filters is run against a set of local images.
By providing two sets of images, one that is relevant and one that is not,
you can understand the quality of the pipeline.

## Upgrade the quality of your collection of images

TODO

# Usage

Set up:

```bash
make create-venv
```

## Search using keywords

Let's download 10 pictures of cats. Meow!

```bash
python -m scripts.scrape2 -q cats -n 10 -o meow
```

There should be 10 cat pictures in the `meow` sub-directory.
If we were to run that query again, we'd download mostly the same images.
That's not very useful.
However, we can use a database to keep track of which images we have downloaded so far,
and avoid downloading them again.
When we specify a database, Similar Images keeps track of what we have downloaded,
and in the future it will exclude images from a known URL,
that have identical contents, or that are almost identical based on hashing techniques.

When we run the following command, the database `db.jsonl` will get populated,
and Similar Images should download pretty much the same images as it did previously.
You can tell by once again looking at `meow` - there should only be 10 images,
the same ones we previously downloaded.
But if we run the command a second time, it won't download the same images twice.
You should now see 10 new images for a total of 20.
You can therefore run Similar Images frequently and have it fetch only new images. 

```bash
python -m scripts.scrape2 -q cats -n 10 -o meow --db db.jsonl
```

We can make things more interesting.
Instead of only searching for cats, let's also search for dogs.
Also, let's make sure we find pets of all sizes.
Similar Images allows specifying [regular expressions](https://github.com/asciimoo/exrex).
We will try to dowload as many images as possible, therefore we'll drop the `-n` parameter.
Because we now have more images to work with, we can be more picky on the ones we download.
Let's make sure all images are fairly large, say least 1500 x 1200 pixels.
Also, so far we have downloaded 1 image at a time, which can be slow.
Let's instead download up to 5 images at once.
Finally, we'll ask Similar Images to be more verbose in its output,
in order to help us better understand the decisions it is making.
Putting it all together:

```bash
python -m scripts.scrape2 -q "(small|medium|big) (cats|dogs)" -o cats_and_dogs --db db.jsonl --min-size=1500,1200 -t 5 -v
```

This made 6 distinct queries to the search engine:
"small cats", "medium cats", "large cats", "small dogs", "medium dogs", and "large dogs".
Regular expressions are a powerful way to get many images!

## Seach using existing images

Another way to find images is to use the "Search using an image" functionality.
Let's take one of the images that we downloaded into `cats_and_dogs`.
Note that due to some limitations, we'll need to run the browser in "visible" mode,
as opposed to "headless" mode as we did previously.
You will see a browser appear on your screen, operated by Similar Images.

```bash
python -m scripts.scrape2 -p ./cats_and_dogs/00242a35.jpeg --visible
```

We can also provide a whole directory:

```bash
python -m scripts.scrape2 -p ./cats_and_dogs --visible
```

Or URLs:

```bash
python -m scripts.scrape2 -p https://www.catster.com/wp-content/uploads/2023/11/selkirk-rex-cat-on-brown-background_mdmmikle_Shutterstock-768x512.jpg --visible
```

# Using LLMs

So far we've used pretty simple filters to reduce the number of images we have to look at -- the size of the image or its similarity to images we already know about.
With Large Language Models (LLMs), we can also write down what we want or don't want to see in an image,
and let the LLM tell us if a given image matches our criteria.
This is often useful as using keywords is limited.
We'll use Gemini from Google, because it works pretty well with images.
To continue with this example, you need to get an [API key](https://ai.google.dev/gemini-api/docs/api-key).

We have already downloaded a fair number of images.
Let's go back over them to find which ones have an animal with an open mouth or green eyes.
First we need to write a configuration to tell Gemini what to do.
Create a file cute_pets.json containing the following:

```json
{
    "model": "gemini-2.0-flash",
    "max_output_tokens": 10,
    "query": "Is this a picture of an animal with either an open mouth or green eyes? Answer by \"yes\" or \"no\"",
    "keep_responses": ["yes"],
    "filter_name": "cute_pets"
}
```

Then we can run the following.
It will look at each image from the first directory and only copy the ones matching our criteria to the second directory.

```bash
export GEMINI_API_KEY=...
python -m scripts.scrape2 -l ./cats_and_dogs -o cute_pets -v -g cute_pets.json
```

## Prompting

TODO

# Development

Run tests:

```bash
make create-venv
make test
```

Note: On Ubuntu, you first need to install a few things:

```bash
sudo apt update
sudo apt install python3.12-venv
```
